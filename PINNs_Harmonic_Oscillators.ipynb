{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e5f70ff",
   "metadata": {},
   "source": [
    "# Physics-Informed Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3d0e2a",
   "metadata": {},
   "source": [
    "Physics-Informed Neural Networks (PINNs) are special types of Neural Networks that incorporate physical laws into their optimization process. This is usually realized by adding physical laws in the form of differential equations (in implicit form) to the cost function. This allows for the wanted solution not only to minimize the prediction error, but also to satisfy already known physical laws. PINNs allow for the integration of a priori scientific knowledge into data-driven ML models and result in better generalizations. This kind of cross between ML and science is often dubbed \"SciML\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dace203",
   "metadata": {},
   "source": [
    "PINNs are mostly unsupervised and mesh-free (i.e. continuous in independent variables). Their convergence properties are not yet well understood, and their computational cost is usually much higher when compared to normal neural networks. They are also poor at scaling to larger domains and complex solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd54116",
   "metadata": {},
   "source": [
    "This project is based on a crash course on PINNs with a guided demonstration by Ben Moseley that is available at the following address: https://youtu.be/G_hIppUWcsc?si=P1-v2H3RiHQ07PfD.\n",
    "Some of the Markdown material (especially LateX-based) is borrowed from the author's Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f69f1db4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa6e5b",
   "metadata": {},
   "source": [
    "### Harmonic Oscillator (Underdamped version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d54857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_solution(delta, w0, t):\n",
    "    \"Analytical solution to the underdamped h.o.\"\n",
    "\n",
    "    assert delta < w0 #for underdampened problem\n",
    "    \n",
    "    w = np.sqrt(w0**2 - delta**2)\n",
    "    phi = np.arctan(-delta/w)\n",
    "    A = 1 / (2*np.cos(phi))\n",
    "    cos = torch.cos(w*t + phi)\n",
    "    exp = torch.exp(-delta * t)\n",
    "    u = 2 * A * exp * cos\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cacd519",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    \"Defines a standard, fully connected Neural Network in PyTorch\"\n",
    "\n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "\n",
    "        self.fcs = nn.Sequential(*[\n",
    "            nn.Linear(N_INPUT, N_HIDDEN),\n",
    "            activation()\n",
    "        ])\n",
    "\n",
    "        self.fch = nn.Sequential(*[\n",
    "                        nn.Sequential(*[\n",
    "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()])\n",
    "                        for _ in range(N_LAYERS-1)\n",
    "        ])\n",
    "\n",
    "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac428d4",
   "metadata": {},
   "source": [
    "### 1. Finding solution to Underdampened Harmonic Oscillator by Training a PINN to simulate the physical system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa280b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "def train_PINN_harmonic_oscillator(STEPS):\n",
    "    \"Trains PINN for the underdamped harmonic oscillator problem using known physical law.\"\n",
    "    #Defining Neural \n",
    "    pinn = FCN(1, 1, 32, 3)\n",
    "\n",
    "    #Defining boundary loss\n",
    "    t_boundary = torch.tensor(0.).view(-1, 1).requires_grad_(True)\n",
    "\n",
    "    #Defining physics loss\n",
    "    t_physics = torch.linspace(0, 1, 30).view(-1, 1).requires_grad_(True)\n",
    "\n",
    "    #Training loop for PINN\n",
    "    d, w0 = 2, 20\n",
    "    mu, k = 2*d, w0**2\n",
    "    lambda1 = 1e-1\n",
    "    lambda2 = 1e-4\n",
    "\n",
    "    t_test = torch.linspace(0, 1, 300).view(-1,1)\n",
    "    #Calculating exact solution\n",
    "    u_exact = exact_solution(d, w0, t_test)\n",
    "    optimizer = torch.optim.NAdam(pinn.parameters(), lr=1e-3)\n",
    "\n",
    "    for i in range(STEPS):\n",
    "        t_boundary = t_boundary.detach().requires_grad_(True)\n",
    "        t_physics  = t_physics.detach().requires_grad_(True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ### Compute terms in full loss function using hyperparameters ###\n",
    "\n",
    "        #Compute boundary losses\n",
    "        u = pinn(t_boundary) #value for u at t=0\n",
    "\n",
    "        #Loss for initial condition: u(t=0) = 1\n",
    "        loss1 = (torch.squeeze(u) -1 )**2\n",
    "\n",
    "        dudt = torch.autograd.grad(u, t_boundary, torch.ones_like(u), create_graph=True)[0] #IMPORTANT DETAIL FOR a tensor of ones that has to to do with the underlying Jacobian computation\n",
    "\n",
    "        #Loss for initial condition: du/dt(t=0) = 0\n",
    "        loss2 = (torch.squeeze(dudt) - 0)**2\n",
    "\n",
    "        #Compute physics losses\n",
    "        u = pinn(t_physics)\n",
    "        dudt = torch.autograd.grad(u, t_physics, torch.ones_like(u), create_graph=True)[0]\n",
    "        d2udt2 = torch.autograd.grad(dudt, t_physics, torch.ones_like(dudt), create_graph=True)[0]\n",
    "        loss3 = torch.mean((d2udt2 + mu*dudt + k*u)**2)\n",
    "\n",
    "        #Backpropagation\n",
    "        loss = loss1 + lambda1 * loss2 + lambda2 * loss3\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ### Plot results during training ###\n",
    "        if  i % 5000 == 0:\n",
    "            u = pinn(t_test).detach()\n",
    "            plt.figure(figsize=(6, 2.5))\n",
    "            plt.scatter(t_physics.detach()[:,0],\n",
    "                        torch.zeros_like(t_physics)[:,0], s=20, lw=0, color=\"tab:green\", alpha=0.6)\n",
    "            plt.scatter(t_boundary.detach()[:,0],\n",
    "                torch.zeros_like(t_boundary)[:,0], s=20, lw=0, color=\"tab:red\", alpha=0.6)\n",
    "            plt.plot(t_test[:,0], u_exact[:,0], label=\"Exact solution\", color=\"tab:grey\", alpha=0.6)\n",
    "            plt.plot(t_test[:,0], u[:,0], label=\"PINN solution\", color=\"tab:green\", alpha=0.6)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "train_PINN_harmonic_oscillator(STEPS = 15001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172edc60",
   "metadata": {},
   "source": [
    "The above example is in reality just a solver of a differential equation (law of underdampened harmonic oscillation) using a Neural Network. Nowhere in these examples are we using actual empirical data/observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d896f82",
   "metadata": {},
   "source": [
    "### 2. Training a PINN to invert for underlying parameters (dampening factor $\\mu$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa8dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f851794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
